{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Networks\n",
    "\n",
    "We'll check out how to build a **convolutional network** to classify CIFAR10 images. By using weight sharing - multiple units with the same weights - convolutional layers are able to learn repeated patterns in your data. For example, a unit could learn the pattern for an eye, or a face, or lower level features like edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "#from torch import nn\n",
    "from torch import optim\n",
    "#import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from data_utils import load_CIFAR10\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train data shape:  (49000, 3, 32, 32)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3, 32, 32)\n",
      "Validation labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = './data/cifar-10-batches-py'\n",
    "    X_train, y_train = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "X_train, y_train = torch.from_numpy(X_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_val, y_val = torch.from_numpy(X_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.LongTensor)\n",
    "\n",
    "traindataset = utils.TensorDataset(X_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=64, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(X_val, y_val)\n",
    "valloader = utils.DataLoader(valdataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, 4 * growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(func.relu(self.bn1(x)))\n",
    "        y = self.conv2(func.relu(self.bn2(y)))\n",
    "        x = torch.cat([y, x], 1)\n",
    "        return x\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_planes)\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(func.relu(self.bn(x)))\n",
    "        x = func.avg_pool2d(x, 2)\n",
    "        return x\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, block, num_block, growth_rate=12, reduction=0.5, num_classes=10):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "        num_planes = 2 * growth_rate\n",
    "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
    "        self.dense1 = self._make_dense_layers(block, num_planes, num_block[0])\n",
    "        num_planes += num_block[0] * growth_rate\n",
    "        out_planes = int(math.floor(num_planes * reduction))\n",
    "        self.trans1 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "        self.dense2 = self._make_dense_layers(block, num_planes, num_block[1])\n",
    "        num_planes += num_block[1] * growth_rate\n",
    "        out_planes = int(math.floor(num_planes * reduction))\n",
    "        self.trans2 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "        self.dense3 = self._make_dense_layers(block, num_planes, num_block[2])\n",
    "        num_planes += num_block[2] * growth_rate\n",
    "        out_planes = int(math.floor(num_planes * reduction))\n",
    "        self.trans3 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "        self.dense4 = self._make_dense_layers(block, num_planes, num_block[3])\n",
    "        num_planes += num_block[3] * growth_rate\n",
    "        self.bn = nn.BatchNorm2d(num_planes)\n",
    "        self.linear = nn.Linear(num_planes, num_classes)\n",
    "\n",
    "    def _make_dense_layers(self, block, in_planes, num_block):\n",
    "        layers = []\n",
    "        for i in range(num_block):\n",
    "            layers.append(block(in_planes, self.growth_rate))\n",
    "            in_planes += self.growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.trans1(self.dense1(x))\n",
    "        x = self.trans2(self.dense2(x))\n",
    "        x = self.trans3(self.dense3(x))\n",
    "        x = self.dense4(x)\n",
    "        x = func.avg_pool2d(func.relu(self.bn(x)), 4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x   \n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out   \n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\python\\lib\\site-packages\\ipykernel_launcher.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15.. Loss: 2.3604.. Test accuracy: 0.2289.. 0.8436 s/batch\n",
      "Epoch: 1/15.. Loss: 2.0345.. Test accuracy: 0.2844.. 0.8056 s/batch\n",
      "Epoch: 1/15.. Loss: 1.9254.. Test accuracy: 0.3076.. 0.8137 s/batch\n",
      "Epoch: 1/15.. Loss: 1.8201.. Test accuracy: 0.3604.. 0.8514 s/batch\n",
      "Epoch: 1/15.. Loss: 1.7230.. Test accuracy: 0.3691.. 0.8257 s/batch\n",
      "Epoch: 1/15.. Loss: 1.7025.. Test accuracy: 0.3809.. 0.8153 s/batch\n",
      "Epoch: 1/15.. Loss: 1.6289.. Test accuracy: 0.3820.. 0.8248 s/batch\n",
      "Epoch: 1/15.. Loss: 1.6287.. Test accuracy: 0.4221.. 0.8161 s/batch\n",
      "Epoch: 1/15.. Loss: 1.6142.. Test accuracy: 0.3887.. 0.8113 s/batch\n",
      "Epoch: 1/15.. Loss: 1.5640.. Test accuracy: 0.4377.. 0.8766 s/batch\n",
      "Epoch: 1/15.. Loss: 1.6196.. Test accuracy: 0.4547.. 0.8730 s/batch\n",
      "Epoch: 1/15.. Loss: 1.5390.. Test accuracy: 0.4170.. 0.8099 s/batch\n",
      "Epoch: 1/15.. Loss: 1.5301.. Test accuracy: 0.4105.. 0.8063 s/batch\n",
      "Epoch: 1/15.. Loss: 1.5271.. Test accuracy: 0.4383.. 0.8074 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4653.. Test accuracy: 0.4691.. 0.8070 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4288.. Test accuracy: 0.4553.. 0.8094 s/batch\n",
      "Epoch: 1/15.. Loss: 1.5108.. Test accuracy: 0.4840.. 0.8120 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4325.. Test accuracy: 0.5057.. 0.8125 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4403.. Test accuracy: 0.4957.. 0.8139 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4190.. Test accuracy: 0.5107.. 0.8073 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3932.. Test accuracy: 0.5080.. 0.8102 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4020.. Test accuracy: 0.5027.. 0.8055 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4896.. Test accuracy: 0.4947.. 0.8070 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3682.. Test accuracy: 0.5266.. 0.8051 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4084.. Test accuracy: 0.5209.. 0.8091 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3349.. Test accuracy: 0.5277.. 0.8131 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3977.. Test accuracy: 0.5309.. 0.9015 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3260.. Test accuracy: 0.5135.. 0.8150 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3417.. Test accuracy: 0.5148.. 0.8099 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3246.. Test accuracy: 0.5197.. 0.8099 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2684.. Test accuracy: 0.5395.. 0.8113 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2301.. Test accuracy: 0.5396.. 0.8192 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3005.. Test accuracy: 0.5594.. 0.8109 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2051.. Test accuracy: 0.5521.. 0.8126 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2451.. Test accuracy: 0.5496.. 0.8098 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2554.. Test accuracy: 0.5559.. 0.8214 s/batch\n",
      "Epoch: 1/15.. Loss: 1.1921.. Test accuracy: 0.5525.. 0.8089 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2147.. Test accuracy: 0.6016.. 0.8120 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1937.. Test accuracy: 0.5594.. 0.5696 s/batch\n",
      "Epoch: 2/15.. Loss: 1.2118.. Test accuracy: 0.5643.. 0.8108 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1487.. Test accuracy: 0.5564.. 0.8150 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1405.. Test accuracy: 0.5902.. 0.8087 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1616.. Test accuracy: 0.5742.. 0.8065 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1735.. Test accuracy: 0.5713.. 0.8118 s/batch\n",
      "Epoch: 2/15.. Loss: 1.2007.. Test accuracy: 0.5643.. 0.8465 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1816.. Test accuracy: 0.5629.. 0.8171 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1743.. Test accuracy: 0.5998.. 0.8151 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0794.. Test accuracy: 0.5961.. 0.8077 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1180.. Test accuracy: 0.6023.. 0.8081 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0978.. Test accuracy: 0.5893.. 0.8172 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1525.. Test accuracy: 0.6004.. 0.8212 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1454.. Test accuracy: 0.5922.. 0.8122 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0907.. Test accuracy: 0.5994.. 0.8129 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0842.. Test accuracy: 0.5998.. 0.8195 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0751.. Test accuracy: 0.6127.. 0.8110 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0812.. Test accuracy: 0.6193.. 0.8146 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0804.. Test accuracy: 0.6299.. 0.8109 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1353.. Test accuracy: 0.6271.. 0.8114 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1236.. Test accuracy: 0.6002.. 0.8087 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0428.. Test accuracy: 0.6199.. 0.8105 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0762.. Test accuracy: 0.6207.. 0.8129 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1256.. Test accuracy: 0.6383.. 0.8145 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0793.. Test accuracy: 0.6105.. 0.8173 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0613.. Test accuracy: 0.6480.. 0.8127 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0501.. Test accuracy: 0.6240.. 0.8120 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0766.. Test accuracy: 0.6264.. 0.8152 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1318.. Test accuracy: 0.6186.. 0.8144 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0487.. Test accuracy: 0.6250.. 0.8191 s/batch\n",
      "Epoch: 2/15.. Loss: 1.1026.. Test accuracy: 0.6379.. 0.8092 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0267.. Test accuracy: 0.6387.. 0.8131 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0568.. Test accuracy: 0.6217.. 0.8132 s/batch\n",
      "Epoch: 2/15.. Loss: 0.9837.. Test accuracy: 0.6514.. 0.8137 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0306.. Test accuracy: 0.6340.. 0.8067 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0055.. Test accuracy: 0.6256.. 0.8064 s/batch\n",
      "Epoch: 2/15.. Loss: 0.9966.. Test accuracy: 0.6338.. 0.8128 s/batch\n",
      "Epoch: 2/15.. Loss: 1.0182.. Test accuracy: 0.6234.. 0.8073 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9964.. Test accuracy: 0.6434.. 0.3239 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9871.. Test accuracy: 0.6471.. 0.8062 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9387.. Test accuracy: 0.6422.. 0.8054 s/batch\n",
      "Epoch: 3/15.. Loss: 1.0174.. Test accuracy: 0.6488.. 0.8062 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9561.. Test accuracy: 0.6514.. 0.8091 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9732.. Test accuracy: 0.6459.. 0.8146 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9118.. Test accuracy: 0.6557.. 0.8417 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9443.. Test accuracy: 0.6510.. 0.8104 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9923.. Test accuracy: 0.6521.. 0.8039 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9744.. Test accuracy: 0.6707.. 0.8074 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9379.. Test accuracy: 0.6598.. 0.8104 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9454.. Test accuracy: 0.6383.. 0.8033 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9731.. Test accuracy: 0.6502.. 0.8093 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9319.. Test accuracy: 0.6438.. 0.8055 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9506.. Test accuracy: 0.6637.. 0.8071 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9379.. Test accuracy: 0.6387.. 0.8058 s/batch\n",
      "Epoch: 3/15.. Loss: 1.0298.. Test accuracy: 0.6697.. 0.8168 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9880.. Test accuracy: 0.6498.. 0.8064 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9298.. Test accuracy: 0.6740.. 0.8022 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9254.. Test accuracy: 0.6584.. 0.8030 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9704.. Test accuracy: 0.6506.. 0.8062 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9458.. Test accuracy: 0.6566.. 0.8098 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9259.. Test accuracy: 0.6680.. 0.8061 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9657.. Test accuracy: 0.6670.. 0.8062 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9282.. Test accuracy: 0.6598.. 0.8052 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9415.. Test accuracy: 0.6451.. 0.8064 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9851.. Test accuracy: 0.6756.. 0.8082 s/batch\n",
      "Epoch: 3/15.. Loss: 0.8867.. Test accuracy: 0.6707.. 0.8017 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9187.. Test accuracy: 0.6689.. 0.8068 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9094.. Test accuracy: 0.6748.. 0.8275 s/batch\n",
      "Epoch: 3/15.. Loss: 0.8834.. Test accuracy: 0.6621.. 0.8047 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9004.. Test accuracy: 0.6746.. 0.8092 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9237.. Test accuracy: 0.6869.. 0.8050 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9917.. Test accuracy: 0.6861.. 0.8112 s/batch\n",
      "Epoch: 3/15.. Loss: 0.9378.. Test accuracy: 0.6764.. 0.8048 s/batch\n",
      "Epoch: 3/15.. Loss: 0.8596.. Test accuracy: 0.6727.. 0.8124 s/batch\n",
      "Epoch: 3/15.. Loss: 0.8919.. Test accuracy: 0.6740.. 0.8083 s/batch\n",
      "Epoch: 3/15.. Loss: 0.8597.. Test accuracy: 0.7049.. 0.8096 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8629.. Test accuracy: 0.6865.. 0.0798 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8194.. Test accuracy: 0.7018.. 0.8104 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8853.. Test accuracy: 0.7020.. 0.8085 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8549.. Test accuracy: 0.6748.. 0.8030 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8298.. Test accuracy: 0.6842.. 0.8079 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8551.. Test accuracy: 0.6842.. 0.8042 s/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15.. Loss: 0.8897.. Test accuracy: 0.6984.. 0.8067 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8639.. Test accuracy: 0.6809.. 0.8056 s/batch\n",
      "Epoch: 4/15.. Loss: 0.7958.. Test accuracy: 0.7016.. 0.8021 s/batch\n",
      "Epoch: 4/15.. Loss: 0.7900.. Test accuracy: 0.6652.. 0.8042 s/batch\n",
      "Epoch: 4/15.. Loss: 0.9324.. Test accuracy: 0.6457.. 0.8021 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8180.. Test accuracy: 0.7051.. 0.8017 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8949.. Test accuracy: 0.7014.. 0.8032 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8577.. Test accuracy: 0.6893.. 0.8081 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8669.. Test accuracy: 0.6949.. 0.8088 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8514.. Test accuracy: 0.7010.. 0.8039 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8271.. Test accuracy: 0.6865.. 0.8049 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8790.. Test accuracy: 0.6771.. 0.8065 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8526.. Test accuracy: 0.6975.. 0.8074 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8696.. Test accuracy: 0.6873.. 0.8097 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8482.. Test accuracy: 0.6916.. 0.8096 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8849.. Test accuracy: 0.7299.. 0.8064 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8545.. Test accuracy: 0.7047.. 0.8065 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8342.. Test accuracy: 0.7078.. 0.8036 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8634.. Test accuracy: 0.7066.. 0.8042 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8323.. Test accuracy: 0.7121.. 0.8111 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8024.. Test accuracy: 0.7086.. 0.8050 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8173.. Test accuracy: 0.7150.. 0.8075 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8472.. Test accuracy: 0.6877.. 0.8109 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8366.. Test accuracy: 0.7020.. 0.8156 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8607.. Test accuracy: 0.7188.. 0.8036 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8004.. Test accuracy: 0.7004.. 0.8249 s/batch\n",
      "Epoch: 4/15.. Loss: 0.7748.. Test accuracy: 0.7002.. 0.8056 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8161.. Test accuracy: 0.7094.. 0.8050 s/batch\n",
      "Epoch: 4/15.. Loss: 0.7854.. Test accuracy: 0.7000.. 0.8098 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8156.. Test accuracy: 0.7066.. 0.8077 s/batch\n",
      "Epoch: 4/15.. Loss: 0.8603.. Test accuracy: 0.6813.. 0.8087 s/batch\n",
      "Epoch: 4/15.. Loss: 0.7754.. Test accuracy: 0.7236.. 0.8085 s/batch\n",
      "Epoch: 4/15.. Loss: 0.7447.. Test accuracy: 0.6932.. 0.8074 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7310.. Test accuracy: 0.7205.. 0.6478 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7616.. Test accuracy: 0.7125.. 0.8045 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7741.. Test accuracy: 0.7133.. 0.8051 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7385.. Test accuracy: 0.7049.. 0.8055 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7075.. Test accuracy: 0.7148.. 0.8097 s/batch\n",
      "Epoch: 5/15.. Loss: 0.8035.. Test accuracy: 0.7162.. 0.8055 s/batch\n",
      "Epoch: 5/15.. Loss: 0.8292.. Test accuracy: 0.7035.. 0.8071 s/batch\n",
      "Epoch: 5/15.. Loss: 0.8064.. Test accuracy: 0.7203.. 0.8051 s/batch\n",
      "Epoch: 5/15.. Loss: 0.8091.. Test accuracy: 0.7205.. 0.8065 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7441.. Test accuracy: 0.7188.. 0.8047 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7408.. Test accuracy: 0.7061.. 0.8164 s/batch\n",
      "Epoch: 5/15.. Loss: 0.6919.. Test accuracy: 0.7219.. 0.7998 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7292.. Test accuracy: 0.7295.. 0.8069 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7371.. Test accuracy: 0.7027.. 0.8082 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7931.. Test accuracy: 0.6918.. 0.8074 s/batch\n",
      "Epoch: 5/15.. Loss: 0.8713.. Test accuracy: 0.7020.. 0.8059 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7507.. Test accuracy: 0.7299.. 0.8086 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7465.. Test accuracy: 0.7256.. 0.8069 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7457.. Test accuracy: 0.7070.. 0.8046 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7679.. Test accuracy: 0.7242.. 0.8056 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7538.. Test accuracy: 0.7277.. 0.8027 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7435.. Test accuracy: 0.7301.. 0.8036 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7140.. Test accuracy: 0.7221.. 0.8015 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7439.. Test accuracy: 0.7324.. 0.8074 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7592.. Test accuracy: 0.7381.. 0.8213 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7311.. Test accuracy: 0.7287.. 0.8063 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7261.. Test accuracy: 0.7420.. 0.8147 s/batch\n",
      "Epoch: 5/15.. Loss: 0.8012.. Test accuracy: 0.7188.. 0.8082 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7715.. Test accuracy: 0.7244.. 0.8028 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7508.. Test accuracy: 0.7061.. 0.8069 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7408.. Test accuracy: 0.7160.. 0.8050 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7122.. Test accuracy: 0.7207.. 0.8031 s/batch\n",
      "Epoch: 5/15.. Loss: 0.6955.. Test accuracy: 0.7424.. 0.8095 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7249.. Test accuracy: 0.7188.. 0.8023 s/batch\n",
      "Epoch: 5/15.. Loss: 0.6874.. Test accuracy: 0.7311.. 0.8055 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7445.. Test accuracy: 0.7334.. 0.8073 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7255.. Test accuracy: 0.7295.. 0.8059 s/batch\n",
      "Epoch: 5/15.. Loss: 0.7622.. Test accuracy: 0.7330.. 0.8072 s/batch\n",
      "Epoch: 6/15.. Loss: 0.7373.. Test accuracy: 0.7408.. 0.4040 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6198.. Test accuracy: 0.7484.. 0.8099 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6617.. Test accuracy: 0.7262.. 0.8028 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6682.. Test accuracy: 0.7324.. 0.8028 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6733.. Test accuracy: 0.7258.. 0.8129 s/batch\n",
      "Epoch: 6/15.. Loss: 0.7100.. Test accuracy: 0.7307.. 0.8067 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6586.. Test accuracy: 0.7475.. 0.8046 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6566.. Test accuracy: 0.7398.. 0.8103 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6402.. Test accuracy: 0.7566.. 0.8061 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6605.. Test accuracy: 0.7383.. 0.8039 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6995.. Test accuracy: 0.7389.. 0.8010 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6842.. Test accuracy: 0.7498.. 0.8002 s/batch\n",
      "Epoch: 6/15.. Loss: 0.7295.. Test accuracy: 0.7322.. 0.8031 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6599.. Test accuracy: 0.7398.. 0.8032 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6758.. Test accuracy: 0.7617.. 0.8104 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6950.. Test accuracy: 0.7576.. 0.8063 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6810.. Test accuracy: 0.7523.. 0.8055 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6673.. Test accuracy: 0.7590.. 0.8078 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6511.. Test accuracy: 0.7297.. 0.8109 s/batch\n",
      "Epoch: 6/15.. Loss: 0.7026.. Test accuracy: 0.7375.. 0.8048 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6746.. Test accuracy: 0.7486.. 0.8093 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6755.. Test accuracy: 0.7482.. 0.8098 s/batch\n",
      "Epoch: 6/15.. Loss: 0.7033.. Test accuracy: 0.7506.. 0.8065 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6900.. Test accuracy: 0.7355.. 0.8059 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6360.. Test accuracy: 0.7473.. 0.8031 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6774.. Test accuracy: 0.7551.. 0.8091 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6362.. Test accuracy: 0.7420.. 0.8066 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6176.. Test accuracy: 0.7266.. 0.8070 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6917.. Test accuracy: 0.7340.. 0.8044 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6930.. Test accuracy: 0.7500.. 0.8034 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6747.. Test accuracy: 0.7436.. 0.8100 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6813.. Test accuracy: 0.7564.. 0.8274 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6795.. Test accuracy: 0.7498.. 0.8096 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6236.. Test accuracy: 0.7502.. 0.8087 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6623.. Test accuracy: 0.7576.. 0.8139 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6822.. Test accuracy: 0.7670.. 0.8060 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6772.. Test accuracy: 0.7719.. 0.8072 s/batch\n",
      "Epoch: 6/15.. Loss: 0.6685.. Test accuracy: 0.7586.. 0.8090 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6551.. Test accuracy: 0.7469.. 0.1629 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5796.. Test accuracy: 0.7502.. 0.8054 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6304.. Test accuracy: 0.7648.. 0.8060 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5474.. Test accuracy: 0.7357.. 0.8083 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6160.. Test accuracy: 0.7533.. 0.8136 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6104.. Test accuracy: 0.7496.. 0.8078 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6036.. Test accuracy: 0.7416.. 0.8104 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6452.. Test accuracy: 0.7428.. 0.8082 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6536.. Test accuracy: 0.7615.. 0.8107 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5940.. Test accuracy: 0.7762.. 0.8121 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5903.. Test accuracy: 0.7557.. 0.8107 s/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/15.. Loss: 0.5920.. Test accuracy: 0.7490.. 0.8086 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6487.. Test accuracy: 0.7596.. 0.8104 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5829.. Test accuracy: 0.7506.. 0.8046 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5729.. Test accuracy: 0.7609.. 0.8057 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6433.. Test accuracy: 0.7619.. 0.8066 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5622.. Test accuracy: 0.7582.. 0.8074 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6141.. Test accuracy: 0.7697.. 0.8021 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6154.. Test accuracy: 0.7561.. 0.8053 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6014.. Test accuracy: 0.7594.. 0.8050 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5998.. Test accuracy: 0.7842.. 0.8124 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6577.. Test accuracy: 0.7629.. 0.8063 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6165.. Test accuracy: 0.7568.. 0.8038 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6043.. Test accuracy: 0.7625.. 0.8056 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6156.. Test accuracy: 0.7533.. 0.8078 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5893.. Test accuracy: 0.7607.. 0.8019 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5719.. Test accuracy: 0.7713.. 0.8093 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5873.. Test accuracy: 0.7537.. 0.8070 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5783.. Test accuracy: 0.7602.. 0.8018 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6071.. Test accuracy: 0.7627.. 0.8114 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6068.. Test accuracy: 0.7740.. 0.8080 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6000.. Test accuracy: 0.7502.. 0.8055 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6448.. Test accuracy: 0.7680.. 0.8049 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6201.. Test accuracy: 0.7648.. 0.8029 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6686.. Test accuracy: 0.7557.. 0.8111 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6162.. Test accuracy: 0.7734.. 0.8072 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6127.. Test accuracy: 0.7629.. 0.8026 s/batch\n",
      "Epoch: 7/15.. Loss: 0.6018.. Test accuracy: 0.7852.. 0.8014 s/batch\n",
      "Epoch: 7/15.. Loss: 0.5906.. Test accuracy: 0.7777.. 0.8116 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5439.. Test accuracy: 0.7785.. 0.7269 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5157.. Test accuracy: 0.7557.. 0.8059 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5069.. Test accuracy: 0.7678.. 0.8105 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5354.. Test accuracy: 0.7748.. 0.8075 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5086.. Test accuracy: 0.7662.. 0.8016 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5280.. Test accuracy: 0.7814.. 0.8026 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5288.. Test accuracy: 0.7541.. 0.8078 s/batch\n",
      "Epoch: 8/15.. Loss: 0.6003.. Test accuracy: 0.7756.. 0.8061 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5567.. Test accuracy: 0.7783.. 0.8023 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5314.. Test accuracy: 0.7717.. 0.8017 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5864.. Test accuracy: 0.7582.. 0.8009 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5608.. Test accuracy: 0.7773.. 0.8045 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5592.. Test accuracy: 0.7734.. 0.8044 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5131.. Test accuracy: 0.7699.. 0.8084 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5232.. Test accuracy: 0.7570.. 0.8012 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5819.. Test accuracy: 0.7852.. 0.8024 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5858.. Test accuracy: 0.7586.. 0.8085 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5856.. Test accuracy: 0.7613.. 0.8164 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5946.. Test accuracy: 0.7812.. 0.8049 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5236.. Test accuracy: 0.7650.. 0.8042 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5659.. Test accuracy: 0.7730.. 0.8094 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5601.. Test accuracy: 0.7771.. 0.8036 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5462.. Test accuracy: 0.7736.. 0.8042 s/batch\n",
      "Epoch: 8/15.. Loss: 0.6267.. Test accuracy: 0.7764.. 0.8021 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5733.. Test accuracy: 0.7686.. 0.8065 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5495.. Test accuracy: 0.7865.. 0.8035 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5262.. Test accuracy: 0.7879.. 0.8121 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5277.. Test accuracy: 0.7783.. 0.8034 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5456.. Test accuracy: 0.7676.. 0.8067 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5402.. Test accuracy: 0.7787.. 0.8085 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5641.. Test accuracy: 0.7705.. 0.8075 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5723.. Test accuracy: 0.7867.. 0.8066 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5923.. Test accuracy: 0.7646.. 0.8062 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5503.. Test accuracy: 0.7826.. 0.8076 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5278.. Test accuracy: 0.7707.. 0.8095 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5733.. Test accuracy: 0.7668.. 0.7999 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5699.. Test accuracy: 0.7695.. 0.8056 s/batch\n",
      "Epoch: 8/15.. Loss: 0.5545.. Test accuracy: 0.7670.. 0.8042 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5459.. Test accuracy: 0.7908.. 0.4875 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4761.. Test accuracy: 0.7840.. 0.8024 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4786.. Test accuracy: 0.7861.. 0.8082 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5354.. Test accuracy: 0.7787.. 0.8086 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4945.. Test accuracy: 0.7873.. 0.8051 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5090.. Test accuracy: 0.7611.. 0.8064 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4533.. Test accuracy: 0.7850.. 0.8028 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4790.. Test accuracy: 0.7725.. 0.8061 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4899.. Test accuracy: 0.7625.. 0.8063 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5092.. Test accuracy: 0.7873.. 0.8059 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5022.. Test accuracy: 0.7613.. 0.8097 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5258.. Test accuracy: 0.7678.. 0.8124 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4981.. Test accuracy: 0.7617.. 0.8074 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5099.. Test accuracy: 0.7729.. 0.8042 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5270.. Test accuracy: 0.7783.. 0.8105 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5308.. Test accuracy: 0.7941.. 0.8060 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4874.. Test accuracy: 0.7744.. 0.8069 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4861.. Test accuracy: 0.7807.. 0.8049 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5249.. Test accuracy: 0.7848.. 0.8044 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5296.. Test accuracy: 0.7848.. 0.8092 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5201.. Test accuracy: 0.7699.. 0.8027 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5465.. Test accuracy: 0.7771.. 0.8064 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5390.. Test accuracy: 0.7994.. 0.8064 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5543.. Test accuracy: 0.7805.. 0.8037 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5169.. Test accuracy: 0.7889.. 0.8033 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5337.. Test accuracy: 0.7734.. 0.8045 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4968.. Test accuracy: 0.7941.. 0.8068 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5438.. Test accuracy: 0.7844.. 0.8128 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5326.. Test accuracy: 0.7789.. 0.8082 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4977.. Test accuracy: 0.7725.. 0.8052 s/batch\n",
      "Epoch: 9/15.. Loss: 0.4907.. Test accuracy: 0.7869.. 0.8092 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5266.. Test accuracy: 0.7885.. 0.8125 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5461.. Test accuracy: 0.7764.. 0.8079 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5329.. Test accuracy: 0.7811.. 0.8096 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5224.. Test accuracy: 0.7992.. 0.8043 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5009.. Test accuracy: 0.7908.. 0.8045 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5433.. Test accuracy: 0.7850.. 0.8081 s/batch\n",
      "Epoch: 9/15.. Loss: 0.5082.. Test accuracy: 0.8025.. 0.8041 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4618.. Test accuracy: 0.7703.. 0.2424 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4872.. Test accuracy: 0.8031.. 0.8078 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4379.. Test accuracy: 0.7873.. 0.8088 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4224.. Test accuracy: 0.7750.. 0.8043 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4274.. Test accuracy: 0.7852.. 0.8092 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4805.. Test accuracy: 0.7943.. 0.8096 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4479.. Test accuracy: 0.7695.. 0.8116 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4616.. Test accuracy: 0.7869.. 0.8102 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4570.. Test accuracy: 0.7879.. 0.8031 s/batch\n",
      "Epoch: 10/15.. Loss: 0.5103.. Test accuracy: 0.7934.. 0.8055 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4303.. Test accuracy: 0.7955.. 0.8058 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4668.. Test accuracy: 0.7682.. 0.8051 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4398.. Test accuracy: 0.7850.. 0.8056 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4543.. Test accuracy: 0.7803.. 0.8127 s/batch\n",
      "Epoch: 10/15.. Loss: 0.3686.. Test accuracy: 0.8004.. 0.8044 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4721.. Test accuracy: 0.7859.. 0.8056 s/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/15.. Loss: 0.5214.. Test accuracy: 0.7934.. 0.8092 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4480.. Test accuracy: 0.8004.. 0.8105 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4752.. Test accuracy: 0.7801.. 0.8135 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4492.. Test accuracy: 0.8049.. 0.8047 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4025.. Test accuracy: 0.7986.. 0.8063 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4400.. Test accuracy: 0.7770.. 0.8065 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4896.. Test accuracy: 0.7867.. 0.8048 s/batch\n",
      "Epoch: 10/15.. Loss: 0.5103.. Test accuracy: 0.7740.. 0.8094 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4530.. Test accuracy: 0.7910.. 0.8044 s/batch\n",
      "Epoch: 10/15.. Loss: 0.5063.. Test accuracy: 0.7746.. 0.8048 s/batch\n",
      "Epoch: 10/15.. Loss: 0.5003.. Test accuracy: 0.7791.. 0.8065 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4977.. Test accuracy: 0.7918.. 0.8060 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4684.. Test accuracy: 0.7887.. 0.8087 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4886.. Test accuracy: 0.7875.. 0.8030 s/batch\n",
      "Epoch: 10/15.. Loss: 0.5310.. Test accuracy: 0.7662.. 0.8076 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4410.. Test accuracy: 0.8008.. 0.8102 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4705.. Test accuracy: 0.7848.. 0.8037 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4721.. Test accuracy: 0.7754.. 0.8044 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4894.. Test accuracy: 0.7791.. 0.8039 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4798.. Test accuracy: 0.7764.. 0.8028 s/batch\n",
      "Epoch: 10/15.. Loss: 0.4650.. Test accuracy: 0.7768.. 0.8036 s/batch\n",
      "Epoch: 10/15.. Loss: 0.5036.. Test accuracy: 0.7666.. 0.8058 s/batch\n",
      "Epoch: 10/15.. Loss: 0.5434.. Test accuracy: 0.7818.. 0.7907 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4448.. Test accuracy: 0.7709.. 0.8126 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4223.. Test accuracy: 0.7924.. 0.8042 s/batch\n",
      "Epoch: 11/15.. Loss: 0.3891.. Test accuracy: 0.7965.. 0.8039 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4093.. Test accuracy: 0.8010.. 0.8071 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4073.. Test accuracy: 0.8006.. 0.8050 s/batch\n",
      "Epoch: 11/15.. Loss: 0.3766.. Test accuracy: 0.7779.. 0.8112 s/batch\n",
      "Epoch: 11/15.. Loss: 0.3947.. Test accuracy: 0.7947.. 0.8005 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4116.. Test accuracy: 0.8096.. 0.8071 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4022.. Test accuracy: 0.7932.. 0.8044 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4318.. Test accuracy: 0.7768.. 0.8067 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4282.. Test accuracy: 0.7951.. 0.8076 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4296.. Test accuracy: 0.7959.. 0.8061 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4347.. Test accuracy: 0.7857.. 0.8112 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4149.. Test accuracy: 0.7887.. 0.8109 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4090.. Test accuracy: 0.7990.. 0.8090 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4121.. Test accuracy: 0.7736.. 0.8210 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4547.. Test accuracy: 0.7937.. 0.8110 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4434.. Test accuracy: 0.7857.. 0.8097 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4743.. Test accuracy: 0.7969.. 0.8504 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4416.. Test accuracy: 0.7830.. 0.8078 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4166.. Test accuracy: 0.7949.. 0.8253 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4172.. Test accuracy: 0.7760.. 0.8048 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4798.. Test accuracy: 0.8035.. 0.8046 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4229.. Test accuracy: 0.7945.. 0.8096 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4531.. Test accuracy: 0.7822.. 0.8293 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4417.. Test accuracy: 0.8006.. 0.8200 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4412.. Test accuracy: 0.7883.. 0.8226 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4279.. Test accuracy: 0.7857.. 0.8182 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4585.. Test accuracy: 0.7812.. 0.8220 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4549.. Test accuracy: 0.7953.. 0.8186 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4347.. Test accuracy: 0.7996.. 0.8274 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4057.. Test accuracy: 0.7896.. 0.8329 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4779.. Test accuracy: 0.7982.. 0.8329 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4916.. Test accuracy: 0.7789.. 0.8244 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4286.. Test accuracy: 0.7898.. 0.8187 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4902.. Test accuracy: 0.7941.. 0.8256 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4094.. Test accuracy: 0.8072.. 0.8219 s/batch\n",
      "Epoch: 11/15.. Loss: 0.4423.. Test accuracy: 0.7965.. 0.8182 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3972.. Test accuracy: 0.7799.. 0.5608 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3756.. Test accuracy: 0.7898.. 0.8059 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4180.. Test accuracy: 0.7977.. 0.8035 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3975.. Test accuracy: 0.8135.. 0.8082 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3791.. Test accuracy: 0.8176.. 0.8043 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3428.. Test accuracy: 0.7859.. 0.8074 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3482.. Test accuracy: 0.8057.. 0.8083 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3860.. Test accuracy: 0.7873.. 0.8066 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3554.. Test accuracy: 0.7887.. 0.7994 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4300.. Test accuracy: 0.7934.. 0.8098 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4155.. Test accuracy: 0.8002.. 0.8031 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3970.. Test accuracy: 0.7924.. 0.8053 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3582.. Test accuracy: 0.7807.. 0.8090 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3724.. Test accuracy: 0.7850.. 0.8061 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3991.. Test accuracy: 0.7744.. 0.8075 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4294.. Test accuracy: 0.7789.. 0.8026 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3701.. Test accuracy: 0.8037.. 0.8064 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3735.. Test accuracy: 0.8178.. 0.8157 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4153.. Test accuracy: 0.7898.. 0.8092 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4047.. Test accuracy: 0.7924.. 0.8064 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4017.. Test accuracy: 0.7908.. 0.8071 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4121.. Test accuracy: 0.7834.. 0.8087 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3599.. Test accuracy: 0.7844.. 0.8065 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4348.. Test accuracy: 0.7895.. 0.8051 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4305.. Test accuracy: 0.7953.. 0.8062 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4018.. Test accuracy: 0.7832.. 0.8069 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4310.. Test accuracy: 0.7920.. 0.8062 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3905.. Test accuracy: 0.7943.. 0.8050 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4338.. Test accuracy: 0.7822.. 0.8060 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4509.. Test accuracy: 0.7918.. 0.8076 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3811.. Test accuracy: 0.7980.. 0.8082 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4117.. Test accuracy: 0.8137.. 0.8061 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4077.. Test accuracy: 0.8057.. 0.8078 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4082.. Test accuracy: 0.7887.. 0.8089 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3667.. Test accuracy: 0.7994.. 0.8136 s/batch\n",
      "Epoch: 12/15.. Loss: 0.3870.. Test accuracy: 0.7729.. 0.8072 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4381.. Test accuracy: 0.7828.. 0.8055 s/batch\n",
      "Epoch: 12/15.. Loss: 0.4146.. Test accuracy: 0.7869.. 0.8068 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3827.. Test accuracy: 0.7826.. 0.3344 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3670.. Test accuracy: 0.8010.. 0.8030 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3401.. Test accuracy: 0.8049.. 0.8045 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3188.. Test accuracy: 0.8131.. 0.8054 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3078.. Test accuracy: 0.7912.. 0.8067 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3308.. Test accuracy: 0.8059.. 0.8035 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3311.. Test accuracy: 0.7914.. 0.8177 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3294.. Test accuracy: 0.8053.. 0.8070 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3386.. Test accuracy: 0.8025.. 0.8051 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3393.. Test accuracy: 0.7957.. 0.8053 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3483.. Test accuracy: 0.8100.. 0.8025 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3489.. Test accuracy: 0.8033.. 0.8055 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3498.. Test accuracy: 0.7990.. 0.8041 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3489.. Test accuracy: 0.7908.. 0.8031 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3685.. Test accuracy: 0.7916.. 0.8065 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3488.. Test accuracy: 0.7832.. 0.8073 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3817.. Test accuracy: 0.7910.. 0.8046 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3610.. Test accuracy: 0.7969.. 0.8018 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3369.. Test accuracy: 0.7924.. 0.8048 s/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/15.. Loss: 0.3497.. Test accuracy: 0.7951.. 0.8045 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3336.. Test accuracy: 0.7967.. 0.8030 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3685.. Test accuracy: 0.7898.. 0.8028 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3743.. Test accuracy: 0.8090.. 0.8050 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3525.. Test accuracy: 0.7877.. 0.8031 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3938.. Test accuracy: 0.7807.. 0.8128 s/batch\n",
      "Epoch: 13/15.. Loss: 0.4196.. Test accuracy: 0.7908.. 0.8042 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3965.. Test accuracy: 0.7857.. 0.8024 s/batch\n",
      "Epoch: 13/15.. Loss: 0.4056.. Test accuracy: 0.7969.. 0.8011 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3453.. Test accuracy: 0.7879.. 0.8051 s/batch\n",
      "Epoch: 13/15.. Loss: 0.4119.. Test accuracy: 0.7977.. 0.8076 s/batch\n",
      "Epoch: 13/15.. Loss: 0.4180.. Test accuracy: 0.7943.. 0.7955 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3912.. Test accuracy: 0.7984.. 0.8066 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3738.. Test accuracy: 0.8025.. 0.8025 s/batch\n",
      "Epoch: 13/15.. Loss: 0.4013.. Test accuracy: 0.7867.. 0.8054 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3773.. Test accuracy: 0.7918.. 0.8042 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3790.. Test accuracy: 0.7855.. 0.8026 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3384.. Test accuracy: 0.7852.. 0.8062 s/batch\n",
      "Epoch: 13/15.. Loss: 0.3522.. Test accuracy: 0.7875.. 0.8044 s/batch\n",
      "Epoch: 14/15.. Loss: 0.4234.. Test accuracy: 0.7811.. 0.0821 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3033.. Test accuracy: 0.7910.. 0.8032 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3048.. Test accuracy: 0.7785.. 0.8071 s/batch\n",
      "Epoch: 14/15.. Loss: 0.2934.. Test accuracy: 0.8064.. 0.8086 s/batch\n",
      "Epoch: 14/15.. Loss: 0.2771.. Test accuracy: 0.7961.. 0.8026 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3084.. Test accuracy: 0.7846.. 0.8039 s/batch\n",
      "Epoch: 14/15.. Loss: 0.2805.. Test accuracy: 0.7895.. 0.8042 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3093.. Test accuracy: 0.7945.. 0.8080 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3475.. Test accuracy: 0.7959.. 0.8104 s/batch\n",
      "Epoch: 14/15.. Loss: 0.2958.. Test accuracy: 0.7891.. 0.8047 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3152.. Test accuracy: 0.7883.. 0.8072 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3246.. Test accuracy: 0.7873.. 0.8042 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3476.. Test accuracy: 0.7889.. 0.8028 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3671.. Test accuracy: 0.7967.. 0.8065 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3184.. Test accuracy: 0.7945.. 0.8082 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3374.. Test accuracy: 0.7994.. 0.8126 s/batch\n",
      "Epoch: 14/15.. Loss: 0.2946.. Test accuracy: 0.7865.. 0.8053 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3264.. Test accuracy: 0.7879.. 0.8061 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3023.. Test accuracy: 0.7734.. 0.8044 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3634.. Test accuracy: 0.7662.. 0.8032 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3313.. Test accuracy: 0.7740.. 0.8022 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3661.. Test accuracy: 0.7834.. 0.8074 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3545.. Test accuracy: 0.8021.. 0.8030 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3430.. Test accuracy: 0.8037.. 0.8061 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3332.. Test accuracy: 0.7902.. 0.8017 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3104.. Test accuracy: 0.8045.. 0.8037 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3310.. Test accuracy: 0.7896.. 0.8086 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3536.. Test accuracy: 0.7918.. 0.8048 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3815.. Test accuracy: 0.7826.. 0.8131 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3903.. Test accuracy: 0.7986.. 0.8036 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3870.. Test accuracy: 0.8064.. 0.8129 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3548.. Test accuracy: 0.7824.. 0.8048 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3788.. Test accuracy: 0.7848.. 0.8043 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3173.. Test accuracy: 0.7924.. 0.8010 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3655.. Test accuracy: 0.7865.. 0.8049 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3653.. Test accuracy: 0.7965.. 0.8070 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3343.. Test accuracy: 0.8037.. 0.8152 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3551.. Test accuracy: 0.7912.. 0.8007 s/batch\n",
      "Epoch: 14/15.. Loss: 0.3406.. Test accuracy: 0.8035.. 0.8081 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2903.. Test accuracy: 0.7984.. 0.6477 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2837.. Test accuracy: 0.7945.. 0.8082 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2426.. Test accuracy: 0.7961.. 0.8045 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2811.. Test accuracy: 0.7924.. 0.8018 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3106.. Test accuracy: 0.7783.. 0.8033 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2884.. Test accuracy: 0.7979.. 0.8015 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2933.. Test accuracy: 0.8080.. 0.8052 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2718.. Test accuracy: 0.7850.. 0.8020 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2775.. Test accuracy: 0.8023.. 0.8037 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2744.. Test accuracy: 0.8064.. 0.8101 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2917.. Test accuracy: 0.7820.. 0.8071 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3164.. Test accuracy: 0.7916.. 0.8037 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2996.. Test accuracy: 0.8008.. 0.8053 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3105.. Test accuracy: 0.8086.. 0.8037 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3040.. Test accuracy: 0.8047.. 0.8140 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2912.. Test accuracy: 0.7928.. 0.8026 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2942.. Test accuracy: 0.7834.. 0.8050 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2469.. Test accuracy: 0.7947.. 0.8083 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3181.. Test accuracy: 0.7893.. 0.8018 s/batch\n",
      "Epoch: 15/15.. Loss: 0.2909.. Test accuracy: 0.7869.. 0.8039 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3237.. Test accuracy: 0.7951.. 0.8062 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3244.. Test accuracy: 0.8064.. 0.8062 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3013.. Test accuracy: 0.7857.. 0.8040 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3748.. Test accuracy: 0.7910.. 0.8049 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3351.. Test accuracy: 0.7941.. 0.8063 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3396.. Test accuracy: 0.7838.. 0.8069 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3566.. Test accuracy: 0.7812.. 0.8041 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3236.. Test accuracy: 0.7961.. 0.8045 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3215.. Test accuracy: 0.7854.. 0.8074 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3511.. Test accuracy: 0.7926.. 0.8054 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3584.. Test accuracy: 0.8016.. 0.8097 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3608.. Test accuracy: 0.7986.. 0.8048 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3250.. Test accuracy: 0.8047.. 0.8073 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3469.. Test accuracy: 0.8143.. 0.8021 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3301.. Test accuracy: 0.8100.. 0.8072 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3242.. Test accuracy: 0.8053.. 0.8123 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3411.. Test accuracy: 0.7998.. 0.8033 s/batch\n",
      "Epoch: 15/15.. Loss: 0.3311.. Test accuracy: 0.8111.. 0.8050 s/batch\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet(BasicBlock, [3, 3, 3])\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01,momentum=0.9)\n",
    "#loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 15\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 20\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        \n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        #                                                                              #\n",
    "        ################################################################################\n",
    "        #pass\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "        ################################################################################|\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        #pass\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        #loss = criterion(output, labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            #net.eval()\n",
    "            #total = 0\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                outputs = net.predict(images)\n",
    "                #predicted = net.predict(outputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total = labels.size(0)\n",
    "                accuracy += ((predicted == labels).sum().item())/total\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                #pass\n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}..\".format(accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch\".format((stop - start)/print_every)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model_resnet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
