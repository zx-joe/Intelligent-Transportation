{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Networks\n",
    "\n",
    "We'll check out how to build a **convolutional network** to classify CIFAR10 images. By using weight sharing - multiple units with the same weights - convolutional layers are able to learn repeated patterns in your data. For example, a unit could learn the pattern for an eye, or a face, or lower level features like edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from data_utils import load_CIFAR10\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Train data shape:  (49000, 3, 32, 32)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3, 32, 32)\n",
      "Validation labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = './data/cifar-10-batches-py'\n",
    "    X_train, y_train = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "X_train, y_train = torch.from_numpy(X_train).type(torch.FloatTensor), torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_val, y_val = torch.from_numpy(X_val).type(torch.FloatTensor), torch.from_numpy(y_val).type(torch.LongTensor)\n",
    "\n",
    "traindataset = utils.TensorDataset(X_train, y_train)\n",
    "trainloader = utils.DataLoader(traindataset, batch_size=64, shuffle=True)\n",
    "\n",
    "valdataset = utils.TensorDataset(X_val, y_val)\n",
    "valloader = utils.DataLoader(valdataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_input_channels=3, n_output=10):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.fc1 = torch.nn.Linear(9 * 64, 200)\n",
    "        self.fc2 = torch.nn.Linear(200, 10)\n",
    "        '''\n",
    "        self.conv32 = torch.nn.Conv2d(n_input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv64 = torch.nn.Conv2d(32, 64,kernel_size=3, padding=1)\n",
    "        self.conv128_1 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv128_2 = torch.nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv256_1 = torch.nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv256_2 = torch.nn.Conv2d(256, 256, kernel_size=5, padding=1)\n",
    "        \n",
    "        self.bn32 = torch.nn.BatchNorm2d(32)\n",
    "        self.bn64 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn128 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn256 = torch.nn.BatchNorm2d(256)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.pool_2 = torch.nn.AvgPool2d(1, 1)\n",
    "        self.fc1 = torch.nn.Linear(256, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "        self.fc = torch.nn.Linear(256, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 3* 32*32)))\n",
    "        x = self.fc2(x)\n",
    "        '''\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.conv32(x)\n",
    "        x = F.relu(self.bn32(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv64(x)\n",
    "        x = F.relu(self.bn64(x)) \n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv128_1(x)\n",
    "        x = F.relu(self.bn128(x))\n",
    "        x = self.conv128_2(x)\n",
    "        x = F.relu(self.bn128(x))      \n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv256_1(x)\n",
    "        x = F.relu(self.bn256(x))\n",
    "        x = self.conv256_2(x)\n",
    "        x = F.relu(self.bn256(x))      \n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.pool_2(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 256) \n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = self.fc(x)\n",
    "\n",
    "        #x = x.view(-1, 16 * 5 * 5)\n",
    "\n",
    "        return x\n",
    " \n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15.. Loss: 2.0260.. Test accuracy: 0.3379.. 0.5578 s/batch\n",
      "Epoch: 1/15.. Loss: 1.7301.. Test accuracy: 0.4445.. 0.5280 s/batch\n",
      "Epoch: 1/15.. Loss: 1.5688.. Test accuracy: 0.4154.. 0.5833 s/batch\n",
      "Epoch: 1/15.. Loss: 1.5003.. Test accuracy: 0.4553.. 0.5259 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4901.. Test accuracy: 0.4859.. 0.5301 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4747.. Test accuracy: 0.4996.. 0.5874 s/batch\n",
      "Epoch: 1/15.. Loss: 1.4116.. Test accuracy: 0.5344.. 0.6406 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3835.. Test accuracy: 0.5227.. 0.6126 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3590.. Test accuracy: 0.5357.. 0.5994 s/batch\n",
      "Epoch: 1/15.. Loss: 1.3184.. Test accuracy: 0.5484.. 0.5783 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2385.. Test accuracy: 0.5521.. 0.5784 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2994.. Test accuracy: 0.5764.. 0.5780 s/batch\n",
      "Epoch: 1/15.. Loss: 1.1830.. Test accuracy: 0.5711.. 0.5898 s/batch\n",
      "Epoch: 1/15.. Loss: 1.2036.. Test accuracy: 0.5611.. 0.5901 s/batch\n",
      "Epoch: 1/15.. Loss: 1.1558.. Test accuracy: 0.5996.. 0.5760 s/batch\n",
      "Epoch: 1/15.. Loss: 1.1697.. Test accuracy: 0.5723.. 0.5815 s/batch\n",
      "Epoch: 1/15.. Loss: 1.1922.. Test accuracy: 0.5895.. 0.5357 s/batch\n",
      "Epoch: 1/15.. Loss: 1.1635.. Test accuracy: 0.5930.. 0.5394 s/batch\n",
      "Epoch: 1/15.. Loss: 1.0908.. Test accuracy: 0.5826.. 0.5386 s/batch\n",
      "Epoch: 1/15.. Loss: 1.0360.. Test accuracy: 0.6135.. 0.5326 s/batch\n",
      "Epoch: 1/15.. Loss: 1.0720.. Test accuracy: 0.6428.. 0.5558 s/batch\n",
      "Epoch: 1/15.. Loss: 1.1082.. Test accuracy: 0.6295.. 0.5383 s/batch\n",
      "Epoch: 1/15.. Loss: 1.0673.. Test accuracy: 0.6371.. 0.5643 s/batch\n",
      "Epoch: 1/15.. Loss: 1.0696.. Test accuracy: 0.6104.. 0.5732 s/batch\n",
      "Epoch: 1/15.. Loss: 1.0688.. Test accuracy: 0.6246.. 0.5769 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9806.. Test accuracy: 0.6322.. 0.5858 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9979.. Test accuracy: 0.6455.. 0.5876 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9815.. Test accuracy: 0.6561.. 0.5800 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9866.. Test accuracy: 0.6369.. 0.5691 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9567.. Test accuracy: 0.6568.. 0.5897 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9220.. Test accuracy: 0.6521.. 0.6711 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9561.. Test accuracy: 0.6777.. 0.5613 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9850.. Test accuracy: 0.6807.. 0.5923 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9664.. Test accuracy: 0.6686.. 0.5742 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9143.. Test accuracy: 0.6895.. 0.5775 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9289.. Test accuracy: 0.6713.. 0.5865 s/batch\n",
      "Epoch: 1/15.. Loss: 0.9131.. Test accuracy: 0.6703.. 0.5851 s/batch\n",
      "Epoch: 1/15.. Loss: 0.8886.. Test accuracy: 0.6908.. 0.5961 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8334.. Test accuracy: 0.6980.. 0.4207 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8554.. Test accuracy: 0.7102.. 0.5813 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8078.. Test accuracy: 0.6828.. 0.5715 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7958.. Test accuracy: 0.6930.. 0.5779 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8504.. Test accuracy: 0.7207.. 0.5797 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8249.. Test accuracy: 0.6896.. 0.6230 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7877.. Test accuracy: 0.6986.. 0.6185 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7729.. Test accuracy: 0.6775.. 0.6145 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8681.. Test accuracy: 0.6934.. 0.5870 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7932.. Test accuracy: 0.6881.. 0.5826 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8204.. Test accuracy: 0.7057.. 0.6031 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8111.. Test accuracy: 0.7021.. 0.6147 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8164.. Test accuracy: 0.7291.. 0.6296 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8192.. Test accuracy: 0.7295.. 0.5910 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8195.. Test accuracy: 0.7285.. 0.5849 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7152.. Test accuracy: 0.7227.. 0.5701 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7249.. Test accuracy: 0.7195.. 0.5842 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7520.. Test accuracy: 0.6986.. 0.6076 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8394.. Test accuracy: 0.7125.. 0.5714 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7707.. Test accuracy: 0.7328.. 0.5993 s/batch\n",
      "Epoch: 2/15.. Loss: 0.8050.. Test accuracy: 0.7273.. 0.5842 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7557.. Test accuracy: 0.7316.. 0.5487 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7706.. Test accuracy: 0.7287.. 0.5363 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7399.. Test accuracy: 0.7367.. 0.5387 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7448.. Test accuracy: 0.7059.. 0.5381 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7943.. Test accuracy: 0.7285.. 0.5349 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7942.. Test accuracy: 0.7115.. 0.5381 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7374.. Test accuracy: 0.7244.. 0.5340 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7681.. Test accuracy: 0.7531.. 0.5341 s/batch\n",
      "Epoch: 2/15.. Loss: 0.6983.. Test accuracy: 0.7533.. 0.5409 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7025.. Test accuracy: 0.7256.. 0.5375 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7808.. Test accuracy: 0.7389.. 0.5382 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7307.. Test accuracy: 0.7264.. 0.5376 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7426.. Test accuracy: 0.7379.. 0.5375 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7480.. Test accuracy: 0.7496.. 0.5394 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7481.. Test accuracy: 0.7443.. 0.5361 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7074.. Test accuracy: 0.7342.. 0.5629 s/batch\n",
      "Epoch: 2/15.. Loss: 0.7020.. Test accuracy: 0.7260.. 0.5857 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6595.. Test accuracy: 0.7496.. 0.2537 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6190.. Test accuracy: 0.7445.. 0.5550 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5984.. Test accuracy: 0.7564.. 0.5537 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5789.. Test accuracy: 0.7393.. 0.5884 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5925.. Test accuracy: 0.7588.. 0.5501 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5893.. Test accuracy: 0.7398.. 0.5432 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6047.. Test accuracy: 0.7299.. 0.5518 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6819.. Test accuracy: 0.7174.. 0.5633 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6732.. Test accuracy: 0.7488.. 0.5505 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6391.. Test accuracy: 0.7520.. 0.5688 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6222.. Test accuracy: 0.7303.. 0.6093 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6286.. Test accuracy: 0.7365.. 0.6104 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6546.. Test accuracy: 0.7449.. 0.5732 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6644.. Test accuracy: 0.7633.. 0.5502 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6156.. Test accuracy: 0.7398.. 0.5396 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5792.. Test accuracy: 0.7641.. 0.5374 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5786.. Test accuracy: 0.7355.. 0.5421 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6360.. Test accuracy: 0.7465.. 0.5377 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6148.. Test accuracy: 0.7471.. 0.5382 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6377.. Test accuracy: 0.7691.. 0.5381 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6011.. Test accuracy: 0.7471.. 0.5394 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6344.. Test accuracy: 0.7547.. 0.5418 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5912.. Test accuracy: 0.7516.. 0.5470 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6056.. Test accuracy: 0.7609.. 0.5390 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5774.. Test accuracy: 0.7404.. 0.5388 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6652.. Test accuracy: 0.7562.. 0.5404 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6143.. Test accuracy: 0.7662.. 0.5607 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6432.. Test accuracy: 0.7377.. 0.5496 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6300.. Test accuracy: 0.7766.. 0.5652 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6542.. Test accuracy: 0.7430.. 0.5929 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5855.. Test accuracy: 0.7609.. 0.6065 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6159.. Test accuracy: 0.7725.. 0.5904 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5341.. Test accuracy: 0.7812.. 0.5918 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6449.. Test accuracy: 0.7727.. 0.6043 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5898.. Test accuracy: 0.7707.. 0.5947 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6264.. Test accuracy: 0.7697.. 0.6155 s/batch\n",
      "Epoch: 3/15.. Loss: 0.5598.. Test accuracy: 0.7555.. 0.6494 s/batch\n",
      "Epoch: 3/15.. Loss: 0.6374.. Test accuracy: 0.7529.. 0.6403 s/batch\n",
      "Epoch: 4/15.. Loss: 0.6646.. Test accuracy: 0.7629.. 0.0677 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4825.. Test accuracy: 0.7740.. 0.6370 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4557.. Test accuracy: 0.7594.. 0.6494 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4147.. Test accuracy: 0.7793.. 0.6316 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4340.. Test accuracy: 0.7686.. 0.6177 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4691.. Test accuracy: 0.7705.. 0.6303 s/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15.. Loss: 0.4361.. Test accuracy: 0.7576.. 0.6095 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4749.. Test accuracy: 0.7736.. 0.6340 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5311.. Test accuracy: 0.7676.. 0.6181 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4967.. Test accuracy: 0.7805.. 0.6074 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5036.. Test accuracy: 0.7625.. 0.6341 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4922.. Test accuracy: 0.7697.. 0.6410 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4755.. Test accuracy: 0.7645.. 0.6033 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4757.. Test accuracy: 0.7637.. 0.5365 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4693.. Test accuracy: 0.7703.. 0.5380 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5137.. Test accuracy: 0.7682.. 0.5395 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5361.. Test accuracy: 0.7797.. 0.5470 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4940.. Test accuracy: 0.7752.. 0.5905 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5233.. Test accuracy: 0.7600.. 0.5747 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4456.. Test accuracy: 0.7830.. 0.5947 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4693.. Test accuracy: 0.7533.. 0.6089 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5275.. Test accuracy: 0.7484.. 0.5960 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5197.. Test accuracy: 0.7490.. 0.5813 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4993.. Test accuracy: 0.7678.. 0.5736 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5181.. Test accuracy: 0.7750.. 0.5902 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4536.. Test accuracy: 0.7652.. 0.6005 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5306.. Test accuracy: 0.7662.. 0.6115 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5034.. Test accuracy: 0.7803.. 0.6011 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4585.. Test accuracy: 0.7855.. 0.5906 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5130.. Test accuracy: 0.7988.. 0.5893 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4907.. Test accuracy: 0.7852.. 0.5823 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5136.. Test accuracy: 0.7564.. 0.6029 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5320.. Test accuracy: 0.7799.. 0.6240 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4970.. Test accuracy: 0.7857.. 0.6143 s/batch\n",
      "Epoch: 4/15.. Loss: 0.5430.. Test accuracy: 0.7793.. 0.6327 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4966.. Test accuracy: 0.7992.. 0.5828 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4531.. Test accuracy: 0.7949.. 0.5911 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4785.. Test accuracy: 0.7902.. 0.6204 s/batch\n",
      "Epoch: 4/15.. Loss: 0.4628.. Test accuracy: 0.7977.. 0.6494 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3929.. Test accuracy: 0.7949.. 0.4519 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3695.. Test accuracy: 0.7863.. 0.5357 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3735.. Test accuracy: 0.7658.. 0.5578 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3977.. Test accuracy: 0.8006.. 0.5346 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3490.. Test accuracy: 0.7816.. 0.5425 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3493.. Test accuracy: 0.7967.. 0.5330 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3780.. Test accuracy: 0.7863.. 0.5612 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3762.. Test accuracy: 0.7801.. 0.5640 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3178.. Test accuracy: 0.7861.. 0.6307 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3407.. Test accuracy: 0.7789.. 0.6349 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3653.. Test accuracy: 0.7732.. 0.5781 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3588.. Test accuracy: 0.7830.. 0.6119 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3578.. Test accuracy: 0.7994.. 0.6038 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3681.. Test accuracy: 0.7854.. 0.5934 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3765.. Test accuracy: 0.7730.. 0.5580 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4188.. Test accuracy: 0.7844.. 0.5739 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4308.. Test accuracy: 0.7801.. 0.6258 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4099.. Test accuracy: 0.7836.. 0.5342 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3930.. Test accuracy: 0.7871.. 0.6003 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4167.. Test accuracy: 0.7957.. 0.5776 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3938.. Test accuracy: 0.7812.. 0.6545 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3887.. Test accuracy: 0.7865.. 0.5963 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3770.. Test accuracy: 0.7781.. 0.5589 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4178.. Test accuracy: 0.7820.. 0.6149 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4019.. Test accuracy: 0.7902.. 0.6339 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4027.. Test accuracy: 0.7854.. 0.6091 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3687.. Test accuracy: 0.7902.. 0.6198 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4097.. Test accuracy: 0.7848.. 0.6113 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4286.. Test accuracy: 0.7910.. 0.5648 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4087.. Test accuracy: 0.7863.. 0.5847 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4320.. Test accuracy: 0.7688.. 0.5589 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3801.. Test accuracy: 0.7666.. 0.6395 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4446.. Test accuracy: 0.7771.. 0.6212 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4220.. Test accuracy: 0.7906.. 0.5736 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4489.. Test accuracy: 0.7824.. 0.6174 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4237.. Test accuracy: 0.7951.. 0.6491 s/batch\n",
      "Epoch: 5/15.. Loss: 0.4132.. Test accuracy: 0.7752.. 0.6293 s/batch\n",
      "Epoch: 5/15.. Loss: 0.3914.. Test accuracy: 0.8004.. 0.5842 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3866.. Test accuracy: 0.7975.. 0.3189 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2508.. Test accuracy: 0.7996.. 0.6480 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2675.. Test accuracy: 0.7898.. 0.6084 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2406.. Test accuracy: 0.7937.. 0.6267 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2620.. Test accuracy: 0.8000.. 0.5854 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2622.. Test accuracy: 0.7937.. 0.6599 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2504.. Test accuracy: 0.7939.. 0.6784 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2640.. Test accuracy: 0.8004.. 0.6108 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2390.. Test accuracy: 0.8061.. 0.5801 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2190.. Test accuracy: 0.7963.. 0.5586 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2259.. Test accuracy: 0.7848.. 0.5706 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2491.. Test accuracy: 0.7832.. 0.5633 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2272.. Test accuracy: 0.7977.. 0.5716 s/batch\n",
      "Epoch: 6/15.. Loss: 0.2901.. Test accuracy: 0.7859.. 0.6059 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3038.. Test accuracy: 0.8023.. 0.5969 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3122.. Test accuracy: 0.7861.. 0.5925 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3202.. Test accuracy: 0.7992.. 0.6103 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3212.. Test accuracy: 0.7746.. 0.5883 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3227.. Test accuracy: 0.7896.. 0.5991 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3119.. Test accuracy: 0.7838.. 0.5539 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3582.. Test accuracy: 0.7797.. 0.5385 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3152.. Test accuracy: 0.7629.. 0.6042 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3485.. Test accuracy: 0.7770.. 0.5705 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3410.. Test accuracy: 0.7863.. 0.5503 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3156.. Test accuracy: 0.8053.. 0.6040 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3141.. Test accuracy: 0.7805.. 0.5809 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3107.. Test accuracy: 0.7828.. 0.5317 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3285.. Test accuracy: 0.7889.. 0.5414 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3166.. Test accuracy: 0.7834.. 0.5835 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3114.. Test accuracy: 0.8039.. 0.6429 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3031.. Test accuracy: 0.7783.. 0.5450 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3089.. Test accuracy: 0.7922.. 0.5276 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3171.. Test accuracy: 0.7863.. 0.5292 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3034.. Test accuracy: 0.7943.. 0.5602 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3211.. Test accuracy: 0.7908.. 0.5724 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3599.. Test accuracy: 0.7775.. 0.5324 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3263.. Test accuracy: 0.7783.. 0.5685 s/batch\n",
      "Epoch: 6/15.. Loss: 0.3586.. Test accuracy: 0.7879.. 0.5965 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2741.. Test accuracy: 0.7936.. 0.1155 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1851.. Test accuracy: 0.8045.. 0.5522 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1606.. Test accuracy: 0.8033.. 0.5459 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1615.. Test accuracy: 0.8146.. 0.5245 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1685.. Test accuracy: 0.7975.. 0.5388 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1860.. Test accuracy: 0.8109.. 0.5247 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1717.. Test accuracy: 0.8133.. 0.5335 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1578.. Test accuracy: 0.8066.. 0.5498 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2271.. Test accuracy: 0.7871.. 0.6247 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1966.. Test accuracy: 0.7963.. 0.5553 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2252.. Test accuracy: 0.8029.. 0.5548 s/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/15.. Loss: 0.2182.. Test accuracy: 0.7957.. 0.5852 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1972.. Test accuracy: 0.8055.. 0.5619 s/batch\n",
      "Epoch: 7/15.. Loss: 0.1928.. Test accuracy: 0.7910.. 0.5535 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2128.. Test accuracy: 0.7898.. 0.5383 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2060.. Test accuracy: 0.7926.. 0.5691 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2088.. Test accuracy: 0.7988.. 0.5853 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2284.. Test accuracy: 0.7902.. 0.5798 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2667.. Test accuracy: 0.7975.. 0.6186 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2199.. Test accuracy: 0.7842.. 0.5599 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2518.. Test accuracy: 0.7883.. 0.5500 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2591.. Test accuracy: 0.7926.. 0.5440 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2688.. Test accuracy: 0.7945.. 0.6083 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2272.. Test accuracy: 0.7965.. 0.5428 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2527.. Test accuracy: 0.8020.. 0.5333 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2838.. Test accuracy: 0.7742.. 0.5509 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2504.. Test accuracy: 0.7838.. 0.5467 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2911.. Test accuracy: 0.7904.. 0.5690 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2368.. Test accuracy: 0.7928.. 0.5446 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2472.. Test accuracy: 0.7896.. 0.5317 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2458.. Test accuracy: 0.7992.. 0.5249 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2185.. Test accuracy: 0.7807.. 0.5238 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2507.. Test accuracy: 0.8033.. 0.5262 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2414.. Test accuracy: 0.7854.. 0.5228 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2559.. Test accuracy: 0.7855.. 0.5248 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2476.. Test accuracy: 0.7932.. 0.5672 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2908.. Test accuracy: 0.7777.. 0.5374 s/batch\n",
      "Epoch: 7/15.. Loss: 0.2470.. Test accuracy: 0.8010.. 0.5758 s/batch\n",
      "Epoch: 7/15.. Loss: 0.3093.. Test accuracy: 0.7900.. 0.5239 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1548.. Test accuracy: 0.7859.. 0.4762 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1499.. Test accuracy: 0.7936.. 0.5245 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1157.. Test accuracy: 0.8068.. 0.5262 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1081.. Test accuracy: 0.7900.. 0.5238 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1207.. Test accuracy: 0.8082.. 0.5221 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1281.. Test accuracy: 0.8047.. 0.5221 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1407.. Test accuracy: 0.7902.. 0.5422 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1398.. Test accuracy: 0.7922.. 0.5280 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1728.. Test accuracy: 0.7916.. 0.5203 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1878.. Test accuracy: 0.7828.. 0.5349 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1791.. Test accuracy: 0.7881.. 0.6051 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1517.. Test accuracy: 0.7865.. 0.6259 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1533.. Test accuracy: 0.7898.. 0.6147 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1671.. Test accuracy: 0.7951.. 0.6173 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1522.. Test accuracy: 0.7811.. 0.5471 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1507.. Test accuracy: 0.7900.. 0.5680 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1558.. Test accuracy: 0.7924.. 0.5416 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1712.. Test accuracy: 0.7945.. 0.5708 s/batch\n",
      "Epoch: 8/15.. Loss: 0.1632.. Test accuracy: 0.7977.. 0.5584 s/batch\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
    "# Choose a critera that measures the loss                                      #\n",
    "################################################################################\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01,momentum=0.9)\n",
    "#loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 15\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 20\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    for images, labels in iter(trainloader):\n",
    "        \n",
    "        steps += 1\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        #                                                                              #\n",
    "        ################################################################################\n",
    "        #pass\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        \n",
    "        \n",
    "        ################################################################################|\n",
    "        # TODO:                                                                        #\n",
    "        # Run the training process                                                     #\n",
    "        #                                                                              #\n",
    "        # HINT: Calculate the gradient and move one step further                       #\n",
    "        ################################################################################\n",
    "        #pass\n",
    "        ################################################################################\n",
    "        #                              END OF YOUR CODE                                #\n",
    "        ################################################################################\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        #loss = criterion(output, labels)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            stop = time.time()\n",
    "            # Test accuracy\n",
    "            #net.eval()\n",
    "            #total = 0\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(valloader):\n",
    "                #outputs = net.predict(images)\n",
    "                #predicted = net.predict(outputs)\n",
    "                #_, predicted = torch.max(outputs.data, 1)\n",
    "                outputs=net.forward(images)\n",
    "                _, predicted = torch.max(F.softmax(outputs).data, 1)\n",
    "                total = labels.size(0)\n",
    "                accuracy += ((predicted == labels).sum().item())/total\n",
    "                ################################################################################\n",
    "                # TODO:                                                                        #\n",
    "                # Calculate the accuracy                                                       #\n",
    "                ################################################################################\n",
    "                #pass\n",
    "                ################################################################################\n",
    "                #                              END OF YOUR CODE                                #\n",
    "                ################################################################################\n",
    "            \n",
    "            print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}..\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}..\".format(accuracy/(ii+1)),\n",
    "                  \"{:.4f} s/batch\".format((stop - start)/print_every)\n",
    "                 )\n",
    "            running_loss = 0\n",
    "            start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model_vgg_32.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
